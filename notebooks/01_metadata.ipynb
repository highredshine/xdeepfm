{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re, glob, random, string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.functions import col, when, array, concat, size\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.functions import vector_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(path, data):\n",
    "    file = open(path, \"w+\")\n",
    "    file.write(json.dumps(data)) \n",
    "    file.close()\n",
    "\n",
    "def get_subpaths(path):\n",
    "    return glob.glob(path)\n",
    "    \n",
    "def generate_cat(size):\n",
    "    return ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(size))\n",
    "\n",
    "def makedir(dir):\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/user/juhochoi/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd()) + \"/\"\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/user/juhochoi/resources/spark/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['SPARK_HOME'] = ROOT_DIR + \"resources/spark/\"\n",
    "os.environ['SPARK_HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/user/juhochoi/data/criteo/'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = ROOT_DIR + \"data/criteo/\"\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/user/juhochoi/data/criteo/full/train.txt'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_DIR = DATA_DIR + \"train/\"\n",
    "DATA_PATH = DATA_DIR + \"full/train.txt\"\n",
    "# TARGET_DIR = DATA_DIR + \"sample/\"\n",
    "# DATA_PATH = TARGET_DIR + \"sample.txt\"\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/user/juhochoi/data/criteo/train/part06/',\n",
       " '/Users/user/juhochoi/data/criteo/train/part01/',\n",
       " '/Users/user/juhochoi/data/criteo/train/part08/',\n",
       " '/Users/user/juhochoi/data/criteo/train/part09/',\n",
       " '/Users/user/juhochoi/data/criteo/train/part00/',\n",
       " '/Users/user/juhochoi/data/criteo/train/part07/',\n",
       " '/Users/user/juhochoi/data/criteo/train/part02/',\n",
       " '/Users/user/juhochoi/data/criteo/train/part05/',\n",
       " '/Users/user/juhochoi/data/criteo/train/part04/',\n",
       " '/Users/user/juhochoi/data/criteo/train/part03/']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCHEMA_PATH = DATA_DIR + \"schema.json\"\n",
    "PART_DIRS = get_subpaths(TARGET_DIR + \"part*/\")\n",
    "PART_DIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/user/juhochoi/resources/spark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/10/11 14:01:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/10/11 14:01:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"pCTR\").\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType.fromJson(json.load(open(SCHEMA_PATH)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"false\").option(\"delimiter\", \"\\t\").schema(schema).csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {\"total\" : df.count()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 10000, 'clicked': 7818, 'non_clicked': 2182}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = df.groupBy(\"label\").count().orderBy('label').collect()\n",
    "count[\"clicked\"] = label_count[0][\"count\"]\n",
    "count[\"non_clicked\"] = label_count[1][\"count\"]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/user/juhochoi/data/criteo/sample/part00/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PART_DIR = PART_DIRS[0]\n",
    "PART_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(PART_DIR + \"count/count.json\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric Features:\n",
    "- significant numbers of missing values\n",
    "- skewed distributions \n",
    "    - should put median rather than mean for null values\n",
    "    - for some features with high-frequency of few values, should use mode rather than median.\n",
    "- large numbers of zeros (described as \"mostly count features\", so okay)\n",
    "\n",
    "[article by Alvira Walin](https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "num_features = [\"i1\", \"i2\", \"i3\", \"i4\", \"i5\", \"i6\", \"i7\", \"i8\", \"i9\", \"i10\", \"i11\", \"i12\", \"i13\"]\n",
    "num_df = df.select(*num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, mean, stddev, mn, _, median, _, mx = num_df.summary().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(df, c):\n",
    "    frequency = df.groupBy(c).count().orderBy(\"count\", ascending = False)\n",
    "    null_count = frequency.filter(df[c].isNull()).collect()\n",
    "    if null_count:\n",
    "        null_cnt = null_count[0][\"count\"]\n",
    "    else:\n",
    "        null_cnt = 0\n",
    "    for row in frequency.head(2):\n",
    "        if row[c] == None:\n",
    "            continue\n",
    "        mode = row[c]\n",
    "        break\n",
    "    return int(mode), null_cnt\n",
    "\n",
    "def key(stat_type, c):\n",
    "    return \"{}({})\".format(stat_type, c)\n",
    "\n",
    "for c in num_df.columns:\n",
    "    stats[key(\"min\", c)] = int(mn[c])\n",
    "    stats[key(\"max\", c)] = int(mx[c])\n",
    "    stats[key(\"avg\", c)] = round(float(mean[c]), 2)\n",
    "    stats[key(\"median\", c)] = int(median[c])\n",
    "    stats[key(\"mode\", c)], stats[key(\"nulls\", c)] = get_mode(num_df, c)\n",
    "    stats[key(\"stddev\", c)] = round(float(stddev[c]), 2)\n",
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(PART_DIR + \"stats/stats.json\", stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "        \"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\", \"c10\", \n",
    "        \"c11\", \"c12\", \"c13\", \"c14\", \"c15\", \"c16\", \"c17\", \"c18\", \"c19\", \"c20\", \n",
    "        \"c21\", \"c22\", \"c23\", \"c24\", \"c25\", \"c26\"\n",
    "    ]\n",
    "cat_df = df.select(*cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabs(dir, df, columns, word_size = 8):\n",
    "    for c in columns:\n",
    "        vocab_list = df.select(c).distinct().toPandas()\n",
    "        while True:\n",
    "            null_feature = generate_cat(word_size)\n",
    "            if null_feature not in vocab_list:\n",
    "                vocab_list = vocab_list.append({c : null_feature}, ignore_index=True)\n",
    "                break\n",
    "        vocab_dir = dir + \"vocabs/\" + c + \"/\"\n",
    "        makedir(vocab_dir)\n",
    "        vocab_list.to_csv(vocab_dir + \"vocabs.csv\", header = False, index = False)\n",
    "        count = {\"count\" : len(vocab_list), \"null_feature\" : null_feature}\n",
    "        write_json(vocab_dir + \"count.json\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part06/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part08/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part09/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part00/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part07/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part05/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part04/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/juhochoi/data/criteo/train/part03/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for part_dir in PART_DIRS:\n",
    "    print(part_dir)\n",
    "    data_path = get_subpaths(part_dir + \"raw/*.txt\")[0]\n",
    "    df = spark.read.option(\"header\", \"false\").option(\"delimiter\", \"\\t\").schema(schema).csv(data_path)\n",
    "    vocabs(part_dir, df, cat_features)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81efb4751146ee777dacf2d48a0600c0d774437cf4ee3d204a1816da91ac0901"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('spark_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
